\section{Проверка оптимизаций, сохраняющих структуру программы}

Опишем стратегию инструмента валидации \emph{voc} \cite{ZPFG02} и теорию валидации оптимизаций.

Компилятор получает на вход \emph{исходную программу}, написанную на высокоуровневом языке, преобразует её в \emph{промежуточное представление} и затем применяет набор оптимизаций к программе --- начиная с классических глобальных оптимизаций, независящих от архитектуры, и заканчивая архитектурно"~зависимыми, такими, как распределение регистров и планирование инструкций. Обычно эти оптимизации производятся в несколько проходов (до 15 в некоторых компиляторах), и каждый проход применяет оптимизацию определённого типа.

Для того, чтобы доказать, что целевой код является корректной трансляцией исходного кода, разберём сначала некоторые необходимые термины. Целевой код \emph{T} является корректной трансляцией исходного кода \emph{S}, если вычисление кода \emph{T} с некоторыми значениями переменных эквивалентно вычислению кода \emph{S} с некоторыми другими значениями переменных.

Промежуточное представление --- это трёхадресный код. Он описан \emph{графом потока}, что является графовым представлением трёхадресного кода. Каждый узел в графе потока представляет собой \emph{линейный участок}, то есть последовательность операторов, не содержащую ветвлений. Границы линейного участка определяются потоком управления.

\subsection{Системы преобразований}

Для представления формальных понятий исходного и промежуточного кода вводится понятие \emph{системы преобразований} (англ. transition systems, $TS$), вариант аналогичного понятия, упомянутого в \cite{PSS98b}. Система преобразований $S = \left\langle  V, O, \Theta, \rho \right\rangle $ --- конечный автомат, где $V$ --- множество переменных состояния, $O \subseteq V$ --- множество наблюдаемых переменных состояния, $\Theta$ --- начальное состояние системы, $\rho$ --- правила перехода, сопостовляющие исходное и результирующее состояние.

Значение, получаемое переменной $x$ в состоянии $s$, обозначается $s[x]$. Правило перехода $y' = y + 1$ означает, что в новом состоянии значение переменной $y$ на 1 больше, чем в старом.

Наблюдаемыми считаются все переменные, значение которых выводится на внешние устройства в результате работы программы.

Система переходов называется детерминированной, если начальное состояние однозначно определяет дальнейший ход вычислений. Мы рассматриваем валидацию только таких программ.

Определим $P_{s} = \left\langle  V_{s}, O_{s}, \Theta_{s}, \rho_{s} \right\rangle $ и $P_{t} = \left\langle  V_{t}, O_{t}, \Theta_{t}, \rho_{t} \right\rangle $ как исходную и целевую систему переходов, соответственно. Они называются сравнимыми, если существует соотношение один"~к"~одному между наблюдаемыми переменными $P_{s}$ и $P_{t}$. Обозначим $ X \subset O_{s} $ и $ x \subset O_{t} $ соответствующие наблюдаемые переменные. Исходное состояние \emph{совместимо} с целевым, если они оба включают одинаковые множества наблюдаемых переменных. Назовём $P_{t}$ корректной трансляцией $P_{s}$ если они сравнимы и, для каждого вычисления $P_{T}$ $\sigma_{T}: t_{0}, t_{1}, \ldots$ и $P_{S}$ $\sigma_{S}: s_{0}, s_{1}, \ldots $ $s_{0}$ совместимо с $t_{0}$, $\sigma_{T}$ завершается тогда и только тогда, когда $\sigma_{S}$ завершается, и их конечные состояния совместимы.

\subsection{Валидация оптимизаций}

Положим $P_{s}$ и $P_{t}$ сравнимыми $TS$. Для формального доказательства корректности преобразования $P_{s}$ в $P_{t}$ введём правило доказательства $Validate$, приведённое ниже. Оно включает в себя установление соответствия потока управления между исходным и целевым кодом и установление соответствия данных между исходным и целевым кодом.

Обе $TS$ имеют множество разрезов $CP$ --- множество участков, включающих начальный и конечный участок и хотя бы один участок из каждого цикла в графе потока управления программы. Простой путь --- путь, соединяющий два места разреза, и не содержащий больше никаких промежуточных узлов. Для каждого простого пути из участка $B_{i}$ в участок $B_{j}$ $\rho_{ij}$ описывает отношение преобразования между участками $B_{i}$ и $B_{j}$.

Инварианты $\phi_{i}$ в части (2) правила --- это аннотации программы, которые должны быть верны при исполнении блока $B_{i}$. Они обычно могут быть получены путём анализа потока данных, который выполняется компилятором.

Условия корректности утверждают, что в каждом переходе из $B_{i}$ в $B_{j}$, при условии соблюдения инварианта $\phi_{i}$ и соотношений между переменными, после перехода соблюдается инвариант $\phi_{j}$ и соотношения между переменными сохраняются.

Работа \cite{ZPFG02} содержит обсуждение, доказательство правильности и примеры применения правила.

Далее приводится правило $Validate$.

\begin{quote}
	\begin{enumerate}
		\item Установить соответствие потока управления $CP_{T} \rightarrow CP_{S}$ между начальным и конечным участком в целевом коде и соответствующими участками в исходном коде.
		\item Для каждого участка $B_{i}$ в $CP_{T}$ сформировать инвариант $\phi_{i}$.
		\item Установить соответствие между данными путём присвоения переменным выражения из переменных состояния в целевом коде, зависимых от выполнения предиката над переменными целевого кода.
		\item Для каждой пары линейных участков $B_{i}$ и $B_{j}$, для которых существует простой путь в графе потока управления, создать множество простых путей и условие корректности
		\item Установить верность всех сгенерированных условий корректности.
	\end{enumerate}
\end{quote}

Проверка сгенерированных условий производится с помощью формальных доказателей теорем вроде используемого в работе \cite{PRSS99}.

Более подробное рассмотрение $Validate$ можно найти в \cite{ZuckPFGH02}.

\section{Проверка трансформаций, изменяющих структуру программы}

Трансформация, изменяющая структуру --- любая трансформация, которая изменяет порядок исполнения кода без добавления или удаления операторов \cite{Bacon,AK02}. Она сохраняет семантику программы в случае сохранения зависимостей между операторами.

\subsection{Обзор трансформаций, изменяющих структуру программы}

Рассмотрим цикл

\begin{center}
	\begin{quote}
		\begin{verbatim}
			for i1 = 1 to k1 do
    			...
				for im = 1 to km do
					B1(i1 ,...,im)
					...
					Bl(i1 ,...,im)
				end
				...
			end
		\end{verbatim}
	\end{quote}
\end{center}

Исполнение такого цикла может быть описано в виде:

\begin{equation}\label{eq:loop-execution}
	\underbrace{B1(i_{1}), B2(i_{1}), \ldots, B\ell(i_{1}),}_{B(i_{1})} 
	\hspace{4mm} \ldots \hspace{4mm} 
	\underbrace{B1(i_{N}), B2(i_{N}), \ldots, B\ell(i_{N})}_{B(i_{N})}.
\end{equation}

Трансформация, изменяющая структуру, вызывает изменение порядка выполнения цикла таким образом, что оно является перестановкой выражения (\ref{eq:loop-execution}).

Более подробное рассмотрение оптимизаций, в том числе и преобразующих циклы, можно найти в источниках \cite{ZuckPFGH02,Bacon}.

Преобразования, изменяющие порядок операторов, можно разбить на 2~класса. Первый меняет расположение элементов $B(i)$, но не меняет порядок операторов внутри $B(i)$. Примеры таких преобразований --- обращение цикла, обмен циклов, разворачивание цикла.

Второй класс преобразований изменяет порядок исполнения компонентов $Bj(i)$ внутри $B{i}$, и оставляет в том же порядке переменную итерации $i$. К таким преобразованиям относится слияние циклов.

Большинство работ рассматривает первый класс преобразований. Каждому преобразованию может быть поставлена в соответветсвие характеристическая перестановка, обозначающая соотношение между индексами массивов в исходном коде и целевом коде.

\subsection{Правила перестановок}

Доказательство с помощью правила $Validate$, приведённое в предыдущем разделе, может быть применено только к программам с одинаковой структурой (путём управления), т.е. оно не может применяться для валидации многих преобразований циклов. В этом разделе мы рассмотрим правила перестановок для проверки преобразований, изменяющих порядок операторов.

Обычно такие трансформации применяются локально, а остальная часть программы оптимизируется только преобразованиями, сохраняющими структуру. Поэтому формально доказать корректность можно с помощью сочетания классического подхода к доказательству с помощью правила $Validate$ и правил перестановок.

Далее рассматриваются только прямые зависимости потока данных. Введение в рассмотрение также анти- и выходных зависимостей представляет из себя тривиальную задачу. Что касается зависимостей по потоку данных, преобразование является корректным, если порядок использования переменной или элемента массива относительно определения остаётся неизменным.

Более подробное описание правил перестановки с примерами можно найти в работе \cite{ZuckPFGH02}.

\subsection{Автоматическая проверка}

Проверка преобразований на основе правил перестановки включает несколько этапов, перечисленных ниже.

\begin{itemize}
	\item Доказательство правильности правил перестановки. Оно осуществляется с помощью формальных доказателей теорем вроде PVS \cite{SOR93}.
	\item Доказательство правильности преобразования и корректности перестановки. Задача осуществления перестановки решается компилятором и подразумевается, что это осуществляется правильно, без доказательства, поскольку эмпирически наблюдаема корректность преобразований в большинстве случаев.
	\item Решение СЛАУ для определения пересечения множеств определений и использований переменных. Эта задача также решается компилятором и подразумевается корретность осуществления решения.
\end{itemize}

В источнике \cite{ZPL00} можно также найти правила перестановки, работающие с более широким кругом преобразований.

\section{Динамическая проверка спекулятивных оптимизаций}

Этот раздел представляет собой обзор проверки \emph{спекулятивных оптимизаций циклов во время исполнения}. В случае, когда ни инструмент проверки, ни компилятор не могут гарантировать корректность преобразования, для проверки верности цикловых оптимизаций используются условия времени выполнения. Эта методика особенно полезна при совпадении областей памяти, адресуемых разными переменными (т.н. \emph{memory aliasing}), что не позволяет применить статический анализ заивисимостей.

В отличие от проверки компилятора, динамическая проверка должна обеспечивать не только контроль правильности работы, но и восстановление безошибочного варианта программы в реальном времени в случае некорректности произведённой спекулятивной оптимизации без произведения неверных результатов. В некоторых случаях возможен выбор оптимизированной версии, которая работает безошибочно; в других же необходим откат к полностью неоптимизированной версии.

Динамическая проверка осуществляется с использованием правил перестановки из предыдущего раздела.

\subsection{Безопасность динамической проверки}

Ниже перечислены свойства, которые должны быть сохранены при введении проверки времени выполнения.

\begin{itemize}
	\item Проверка должна обнаруживать, точно или консервативно, нарушение зависимостей по данным в оптимизированном цикле.
	\item Как только динамическая проверка обнаруживает возможное нарушение зависимостей, должен быть произведён переход на путь управления, который приведёт к произведению верного результата.
	\item Динамическая проверка должна быть способна определить нарушение зависимости до того, как оно произошло.
\end{itemize}

Последнее свойство, возможно, является слишком строгим. Оно может быть заменено требованием в случае обнаружения нарушения пост"~фактум возможности исполнить код, который исправит неверные результаты.

\subsection{Проблемы эффективности динамической проверки}

Для того, чтобы иметь практический смысл, динамическая проверка должна иметь качественные характеристики, приведённые далее.

\begin{itemize}
	\item Проверка времени выполнения должна происходить как можно более редко.
	\item Проверка должна быть как можно более дешёвой в терминах вычислительной сложности и занимаемой памяти.
	\item Стоимость исполнения цикла в случае обнаружения потенциального нарушения должна быть не больше, чем стоимость исполнения оригинального (неоптимизированного) цикла.
\end{itemize}

В работе \cite{ZuckPFGH02} разработан набор методик динамической оптимизации, которые в разной степени удовлетворяют этим требованиям.

\subsection{Обнаружение нарушения зависимости}

Обнаружение нарушения до того, как оно произошло, представляет определённые сложности. Без учёта этого ограничения можно использовать довольно эффективный алгоритм для проверки корректности оптимизированного цикла. Его можно найти в источнике \cite{ZuckPFGH02}. Этот алгоритм прост в реализации, но имеет 2 отрицательные черты:

\begin{enumerate}
	\item он требует столько же дополнительной памяти, каков размер итерируемого массива;
	\item он не обнаруживает нарушения до того, как оно произошло.
\end{enumerate}

Вторая черта делает алгоритм бесполезным в реальной динамической проверке, поскольку если на какой"~то итерации производится неверное значение, затем оно используется на следующей, делая все результаты работы программы неверными.

\subsection{Ограничение множества определений}

В большинстве случаев одно из множеств --- определений или использований --- может быть проанализировано статически. И хотя полностью статический анализ в таком случае невозможен, данная ситуация значительно проще той, в которой оба множества не поддаются анализу. В таком случае возможен анализ с помощью компилятора, как описано в работе \cite{ZuckPFGH02}.

Дальнейшие примеры преобразований и их проверки можно также найти в источнике \cite{ZuckPFGH02}.

\subsection{Архитектурные соображения}

Создание проверок времени выполнения становится более важным ввиду распространения новых классов процессоров, которые обладают чертами, приведёнными ниже.

\begin{itemize}
	\item Предоставляют возможности эксплуатировать параллелизм на уровне инструкций;
	\item Имею аппаратные особенности, делающие незначительными расходы на проверку и исправление результатов в случае нарушения зависимостей.
\end{itemize}

Большинство современных процессоров имеют множество функциональных единиц для эксплуатации параллелизма на уровне инструкций с помощью динамического планирования исполнения нескольких инструкций одновременно на суперскалярных машинах или с помощью сгенерированных компилятором параллельных инструкций (в случае VLIW"~процессоров). Сложностью использования VLIW"~машин оказалась трудность нахождения достаточного параллелизма на уровне инструкций с целью использовать все доступные функциональные единицы машины. Таким образом, динамическая проверка может использовать незадействованные в вычислениях модули процессора.

Некоторые аппаратные характеристики архитектур, таких, как Intel IA"~64, позволяют улучшить поддержу динамической проверки корректности. В частности, это аппаратно реализованные инструкции динамической проверки на адресацию одной и той же области памяти многими указателями. Возможность устанавливать предикаты на пути исполнения этой архитектуры также помогает избежать исполнения некорректного кода до того, как оно произошло. Более подробно об этом можно прочитать в статье \cite{GHCP02}.

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}%

Мы рассмотрели подходы к формальной проверке правильности программ, а именно статическую проверку и динамическую проверк; их сильные и слабые стороны и сделали обзор механизмов реализации проверки.

Мы рассмотрели способы проверки корректности цикловых оптимизаций и предложили специальную методику для преобразований, изменяющих порядок исполнения операторов, состояющую в добавлении проверяющего и корректирующего кода в компилируемую программу. Этот инструментирующий код обнаруживает нарушения зависимостей и предотвращает порчу результатов работы программы.