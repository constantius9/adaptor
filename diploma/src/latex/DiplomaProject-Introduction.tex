\section{Введение}
Разработка современного математического обеспечения САПР "--- сложная задача, требующая больших вложений материальных и временных ресурсов. Зачастую для достижения оптимальности по таким критериям, как производительность, объём занимаемой памяти, и энергопотребление требуется ручная настройка компилятора "--- выбор вариантов тонких настроек оптимизации под определённую программно-аппаратную платформу с учётом особенностей решаемой задачи. Это плохо формализованная задача, которая часто решается разработчиками МО методом проб и ошибок. В результате этого оптимальность часто не достигается ни по одному из выбранных критериев.

Распространённой проблемой для исследователей и инженеров является то, что параметры компиляции подбираются под конкретный набор входных данных, на конкретной программно-аппаратной платформе. При этом для набора данных, встречающегося в реальных задачах (а не используемого во время подбора оптимальных параметров), оптимальные параметры могут оказаться иными.

Для увеличения возможностей по тонкой оптимизации математического программного обеспечения для рабочих станций и суперкомпьютеров необходима формализация поисковой области. С помощью построения модели производительности программ возможно достичь лучшего понимания воздействия оптимизаций компилятора на интересующие разработчика критерии эффективности программы. Таким образом можно сделать поиск оптимальных настроек более направленным и локализованным, сокращая цикл разработки математического обеспечения, стоимость разработки и поддержки.


\subsection{Цель}
Цель — разработать систему сбора, систематизации, формализации данных о производительности компилируемых программ в зависимости от настроек компилятора и программно-аппаратной платформы, а также выполняющую функции поддержки базы знаний и обучения с целью моделирования и предсказания эффективности программ.

Примером критерия эффективности является производительность программы на данной программно-аппаратной платформе.


\subsection{Задачи}
\begin{enumerate}
\item Задача
\end{enumerate}


\section{Обзор области автоматической настройки компилятора}
\subsection{Технологии компиляторов}
Современный оптимизирующий промышленный компилятор "--- сложная программа, состоящая из нескольких модулей, типично выделяемых в две части~\cite{Aho:2006:CPT:1177220}, описанные ниже.
\begin{enumerate}
	\item Анализирующая часть.
	\begin{enumerate}
		\item Лексический анализатор. Распознаёт строки (<<лексемы>>) и формирует из них типизированные значения (<<токены>>).
		\item Синтаксический анализатор. Потребляет токены и анализирует грамматическую правильность сформированных из них конструкций.
		\item Семантический анализатор. Производит семантический анализ --- оценивает правильность и осмысленность сформированных из токенов конструкций.
	\end{enumerate}
	\item Синтезирующая часть.
	\begin{enumerate}
		\item Генератор абстрактного синтаксического дерева. Производит построение абстрактного синтаксического дерева из токенов. Дерево отражает связи между различными элементами исходного файла, но уже не привязано к их строковому представлению. Оно содержит множество типизированных узлов со связями между ними.
		\item Генератор промежуточного представления. Создаёт промежуточное представление (такое как трёхадресный код или форма с статическим единственным присваиванием) из абстрактного синтаксического дерева. Также может конвертировать одно промежуточное представление в другое для удобства произведения оптимизаций.
		\item Оптимизатор. Производит трансформацию промежуточного представления с сохранением семантики и увеличением эффективности. Типичными оптимизациями являются уменьшение сложности операции и разворачивание циклов. Обычно использует набор эвристик, определяющих правила применения оптимизаций и их параметры, т.к. многие оптимизации имеют настройку того или иного рода, определяющие её агрессивность.
		\item Генератор исполняемого файла. Производит окончательное создание исполняемого файла в двоичном формате: перевод промежуточного представления в набор инструкций целевой машины, оптимизации на объектном файле и связывание объектных файлов в исполняемый.
	\end{enumerate}
\end{enumerate}

Стоит отметить, что данное деление является довольно условным: так, синтаксический анализатор, семантический анализатор и генератор абстрактного синтаксического дерева типично объединяются в одну единицу, называемую <<парсер>>. Однако, оно довольно показательно с точки зрения объёма и разнообразия задач, решаемых компилятором.


\subsection{Сложность разработки компиляторов}
Разработка современного оптимизирующего промышленного компилятора "--- сложная задача, требующая огромных вложений человеческих ресурсов. Больш\'{а}я часть этой сложности обусловлена необходимостью тонкой настройки эвристических методов оптимизации исполняемого кода (которые в общем случае решаются NP-сложными алгоритмами), производимой вручную путём просмотра генерируемого кода и состояний промежуточного представления компилятора. Не говоря о том, что само по себе создание таких эвристик представляет собой зачастую нетривиальную задачу \cite{Muchnick:2004:EIS:989393.989413,Lavery:1995:IPC:626512.626987,Abraham:1996:MSR:243846.243903}, эвристики часто имеют противоположные цели "--- например, одни оптимизации увеличивают производительность кода ценой размера исполняемого файла (например, разворачивание циклов), а другие уменьшают размер кода, уменьшая производительность. Помимо этого, в компиляторах чаще всего используются упрощённые модели аппаратного обеспечения, не учитывающие многие эффекты даже первого порядка, не говоря уже о побочных эффектах. Более того, сами правила обнаружения случаев, в которых можно оптимизировать код, создаются человеком, что также трудоёмко и является далеко не исчерпывающим способом увеличения производительности результирующего кода. Помимо этого, от порядка произведения оптимизаций часто зависит итоговая производительность и размер кода исполняемого файла.

В то же время, у настроек эвристик есть фокальные точки "--- такие настройки оптимизации, при которых достигается оптимум по какому-либо критерию. Эти фокальные точки могут быть найдены с помощью функции цели. Примером задачи, для которой существуют достаточно хорошие целевые функции, является задача распределения регистров.

В существующих компиляторах также стоит проблема подбора оптимальных настроек компиляции для данной конкретной программы. Чаще всего проще ограничиться стандартной настройкой <<максимальная производительность>>, нежели производить трудоёмкий анализ кода, который так же требует квалификации опытного разработчика компилятора и знания о платформе, для которой генерируется исполняемый файл. Эта задача также может решаться автоматически и, в ряде случаев, более эффективно.


\subsection{Подходы к решению проблемы сложности эвристик}
Попытки настраивать и даже синтезировать \cite{Stephenson:2006:ACC:1269626,Stephenson:2003:MOI:780822.781141} эвристики предпринимались неоднократно. Как уже показали работы \cite{Agakov:2006:UML:1121992.1122412,Bodin98iterativecompilation,FCA2007,Cooper:2005:AAC:1065910.1065921}, задача подбора самих эвристик и их настройки может решаться автоматически.

Принципиально, классическим подходом к этой задаче является итеративная компиляция. Также, в последнее время получили распространение методы машинного обучения и коллективной оптимизации. Далее мы рассмотрим эти подходы.


\subsection{Итеративная компиляция}
Итеративная компиляция "--- методика поиска оптимальных по некоторому критерию настроек компилятора, при которой компилируемая программа собирается много раз с одним набором данных на одной и той же программно-аппаратной платформе с разными, выбираемыми, как правило, случайным образом, настройками, с последующим запуском и замером интересующих факторов во время её выполнения (например, времени выполнения). Очевидно, что такой подход страдает от чудовищной неэффективности --- поиск оптимальных настроек для одной программы может занимать месяц машинного времени. Количество необходимых компиляций составляет десятки и сотни запусков \cite{Kisuki:1999:FSI:646347.690219}. Кроме того, такой поиск является весьма ограниченным, поскольку найденные настройки в итоге подходят только для данного набора данных на данной платформе с данным компилятором (вплоть до конкретной версии), и практически никаких общих рекомендаций извлечь из этого процесса не получается.

Неоднократно производились попытки ускорить этот процесс с помощью применения различных методов оптимизации, изменяющих характер поиска настроек с случайного на более направленный. В этом случае задача осложняется чрезвычайно большой многомерностью такой оптимизации "--- признаков, по которым опознаются программы и которые можно считать аргументами функции эффективности, насчитываются десятки (имеются ввиду такие признаки, собираемые с исходного кода программы, как средняя глубина вложенности циклов, среднее число вызовов процедур на блок и т.д.). Таким образом, данный способ решения является крайне плохо приспособленным для реального применения.


\subsection{Машинное обучение}
Недавние работы в данной области показали возможность увеличить эффективность итеративной компиляции с помощью машинного обучения, позволяя обеспечить компилятор возможностью подстраиваться под сложные архитектуры и повысить его производительность относительно классических статических компиляторов "--- т.е. таких, которые не были специально модифицированы для работы с инструментарием машинного обучения \cite{Dubach:2009:PCO:1669112.1669124,Dubach:2008:EPA:1450095.1450103}.

Далее для понимания связи машинного обучения с компиляцией приведена классическая постановка задачи этого раздела науки.

Имеется множество объектов (ситуаций) и множество возможных ответов (откликов, реакций). Существует некоторая зависимость между ответами и объектами, но она неизвестна. Известна только конечная совокупность прецедентов "--- пар <<объект, ответ>>, называемая обучающей выборкой. На основе этих данных требуется восстановить зависимость, то есть построить алгоритм, способный для любого объекта выдать достаточно точный ответ. Для измерения точности ответов определённым образом вводится функционал качества.

В нашем случае объектом является исходный код программы с его признаками (такими, как средний размер массивов и среднее число итераций циклов), а ответом "--- значение интересующего нас фактора во время исполнения программы (например, объём занимаемой памяти).

Стоит отметить, что предпочтительным является обучение с использованием только производственных запусков компилятора, т.е. без специальных обучающих запусков. Для этого предлагается использовать коллективную оптимизацию, позволяющую пользователям обмениваться данными об успешной оптимизации и не проделывать избыточную работу каждый раз изолированно.


\subsection{Коллективная оптимизация}
Коллективная оптимизация предполагает реализацию некого инструментария, подключаемого к компилятору с целью организации его прозрачной работы с общим репозиторием настроек компиляции. Этот подход является многообещающим, но не лишён сложностей.

А именно, перед реализацией коллективной оптимизации стоит несколько проблем исследовательского и инженерного характера. Инженерная проблема состоит в создании системы, позволяющей прозрачно переиспользовать накопленные другими пользователями знания о произведенных компиляциях и отправлять данные о них без дополнительных действий со стороны конечного пользователя компилятора. Частью решения этой проблемы является плагин к компилятору GCC, предоставляющий возможности произвольного включения выбранных проходов компилятора и обеспечивающий его взаимодействие с репозиторием кода cTuning.org \cite{Fur2009}. В случае более современного компилятора llvm \cite{llvm} плагин имеет более простую организацию, поскольку данный инструмент имеет встроенные возможности произвольного выбора набора производимых оптимизаций, и нужно обеспечить только взаимодействие с репозиторием cTuning. Исследовательская проблема состоит в изучении воздействия различных оптимизаций на различные факторы получаемых программ, такие, как время исполнения и объём используемой памяти.

Коллективная оптимизация может обеспечить эффективность итеративной компиляции без произведения такого большого количества избыточных запусков компилятора. Одним из успешно применяемых подходов к этой задаче предполагает статистическое сравнение эффективности пар наборов оптимизаций. Недавние работы также обнаружили значительно б\'{о}льшую важность обучения на различных наборах данных и на различных архитектурах, нежели обучения на различных программах \cite{springerlink:10.1007/11596110:24}. Это опровергает доминировавшую до этого точку зрения на применение машинного обучения в компиляторах и предлагает новые перспективы в области автоматической настройки компиляции.