\section{Введение}
Разработка современной компьютерной системы "--- сложная задача, требующая больших вложений материальных и временных ресурсов. Б\'{о}льшая часть компьютерных систем разрабатываются большими компаниями итерационно, на протяжении периодов в два и более лет, и базируясь на предыдущих архитектурах. При этом сохраняется обратная совместимость новых решений с уже разработанными. Такой процесс происходит и в области разработки аппаратного обеспечения, и в области разработки программ.

При этом большинство пользователей компьютерных систем никаким образом не принимают участие в разработке компьютера. Это ограничивает возможности учесть реальные потребности пользователей в процессе разработки. В большинстве случаев проектирование происходит относительно независимыми инженерами, которые исходят из своих предположений о нуждах <<среднего пользователя>>. Однако эти предположения могут оказаться неверными, и одной из причин этого может стать длинный и независимый цикл разработки как аппаратного, так и программного обеспечения. В течение всего цикла разработки начальные требования к результату практически никак не корректируются. Само по себе проектирование чаще происходит с целью максимизации прибыли от последующей реализации продукта, нежели с целью удовлетворения потребностей пользователей.

Это не всегда происходит осознанно "--- частой проблемой является огромная база пользователей и противоречивость их запросов. Примером может служить проектирование очередного обновления процессора с архитектурой \textit{x86-64} и операционной системы общего назначения \textit{Windows}. Одним пользователям нужны портативные компьютеры на данной платформе, другим "--- настольные или серверные; кому-то нужна высокая производительность в играх, а кому-то "--- низкие энергопотребление и уровень шума, и т.\,д.~и~т.\,п.


\subsection{Мотивация}
\begin{enumerate}
\item Многие исследования показывают потенциал, но плохо систематизированы.
\item Инженерная задача по созданию инфраструктуры для коллективной оптимизации не решена до сих пор.
\item Конечным пользователям компиляторов мешает именно отсутствие инструментария, который помог бы им пользоваться обучаемым компилятором так же, как обычным (интерфейс чёрного ящика).
\item В целом это популярная в последнее время тема --- Intel запустил Exascale Lab, также IBM и ARM очень заинтересованы и хотят финансировать эти исследования.
\end{enumerate}

\subsection{Цель}
Цель — разработать систему сбора, систематизации, формализации данных о производительности компилируемых программ в зависимости от настроек компилятора, а также выполняющую функции поддержки базы знаний и обучения с целью:
\begin{enumerate}
\item Предсказания производительности программ
\item Оптимизации производительности программ путём изменения настроек компилятора
\end{enumerate}

Пока рассматриваем только 1 критерий --- производительность.

\subsection{Задачи}
\begin{enumerate}
\item {Выполнить первоначальное наполнение репозитория данными.
Установить окружение и репозиторий локально и внести туда программы из центрального репозитория.
Собрать небольшое количество признаков для начала работы.\\
Предполагаемый объём работы от общего: 5\%.}
\item {Пронаблюдать влияние набора данных, компилятора и архитектуры на производительность. 
Для этого попробовать перебор разных комбинаций этих параметров (в числе которых и настройки компилятора) и сравнить получаемые результаты. Это нужно для набора данных для последующего машинного обучения на них. 
Это не полный перебор, а небольшой просмотр области поиска с целью выяснения реакции программ на изменения для последующей формализации модели производительности.\\
Предполагаемый объём работы от общего: 10\%.}
\item {Формализовать признаки программ, влияние платформы и настроек компилятора на производительность.
Строим модель производительности программы. Это будет делаться изначально вручную с последующими попытками обобщить до автоматического выбора модели с помощью машинного обучения. Пример: начать с линейной регрессии от одного признака (размера входных данных), дальше обнаруживать нестыковки и добавлять новые признаки.
Полезными моделями могут быть вероятностная (она удобна для представления сравнения 2 программ и легко интерпретируется для понимания человеком), деревья решений (легко интерпретируется, относительно быстро строится и работает).
Другие методы, такие как SVM и kNN, могут тоже быть полезны и возможно будут использоваться — но они лишены такой черты, как простота понимания, почему именно такое решение было выбрано моделью. Это затрудняет дальнейшее развитие проекта (поскольку непонятно, в каком месте модели произошла ошибка). Также, применение методов “ad-hoc” не даёт воспроизводимых результатов, на которых можно хорошо строить модель.\\
Предполагаемый объём работы от общего: 35\%.}
\item {Построить предсказывающий модуль
Он может работать в 2 режимах:
	\begin{enumerate}
	\item Предсказание уровня производительности программы при заданных входных параметрах. Полезно в облачных сервисах и параллельных вычислениях (балансировка загрузки). Это регрессионный анализ.
	\item Выбор оптимальных настроек компилятора для получения максимальной производительности при заданной платформе, программе (которой ещё нет в репозитории известных программ) и множестве наборов входных данных. Возможны даже рекомендации по выбору другого компилятора. Это классификация.
	\end{enumerate}
Сюда же попадает первоначальное обучение предсказателя для начала работы системы.\\
Предполагаемый объём работы от общего: 25\%.}
\item {Анализировать проблемы предсказателя (ошибки неправильной классификации или регрессии) с целью улучшить работу.
Это включает в себя как ручной просмотр моделей экспертами с помощью нашего интрументария (без него это делать крайне неудобно) с целью понимания возможной проблемы, так и попытки автоматически улучшить модель с помощью добавления новых признаков или настроек, не учтённых в модели для этого.
Сюда же попадает дообучение при получении новых данных, таких как запуск программы с новыми данными, на новой платформе или с новым компилятором, или данные о новых программах.\\
Предполагаемый объём работы от общего: 20\%}
\item {Улучшить интеграцию в существующие компиляторы, так чтобы для конечного пользователя работа системы происходила прозрачно (интерфейс работы с компилятором не изменялся). Это нужно для вовлечения большего числа разработчиков и экспертов в компьютерных системах для выявления проблем моделей на этапе 5.\\
Предполагаемый объём работы от общего: 5\%.}
\end{enumerate}

Реализация будет использовать Python в качестве основного языка с возможными вызовами scipy и R для реализации сложной обработки данных. Это простой и удобный, популярный и хорошо поддерживаемый язык с большим количеством библиотек. В случае необходимости можно достигнуть высокой производительности с помощью компилятора PyPy.

\section{Обзор области автоматической настройки компилятора}
\subsection{Технологии компиляторов}
Современный оптимизирующий промышленный компилятор --- сложная программа, состоящая из нескольких модулей, типично выделяемых в 2 части \cite{Aho:2006:CPT:1177220}:
\begin{enumerate}
	\item Анализирующая часть
	\begin{enumerate}
		\item Лексический анализатор. Распознаёт строки («лексемы») и формирует из них типизированные значения («токены»).
		\item Синтаксический анализатор. Потребляет токены и анализирует грамматическую правильность сформированных из них конструкций.
		\item Семантический анализатор. Производит семантический анализ --- оценивает правильность и осмысленность сформированных из токенов конструкций.
	\end{enumerate}
	\item Синтезирующая часть
	\begin{enumerate}
		\item Генератор абстрактного синтаксического дерева. Производит построение абстрактного синтаксического дерева из токенов. Дерево отражает связи между различными элементами исходного файла, но уже не привязано к их строковому представлению. Оно содержит множество типизированных узлов со связями между ними.
		\item Генератор промежуточного представления. Создаёт промежуточное представление (такое как трёхадресный код или форма с статическим единственным присваиванием) из абстрактного синтаксического дерева. Также может конвертировать одно промежуточное представление в другое для удобства произведения оптимизаций.
		\item Оптимизатор. Производит трансформацию промежуточного представления с сохранением семантики и увеличением эффективности. Типичными оптимизациями являются уменьшение сложности операции и разворачивание циклов. Обычно использует набор эвристик, определяющих правила применения оптимизаций и их параметры, т.к. многие оптимизации имеют настройку того или иного рода, определяющие её агрессивность.
		\item Генератор исполняемого файла. Производит окончательное создание исполняемого файла в двоичном формате: перевод промежуточного представления в набор инструкций целевой машины, оптимизации на объектном файле и связывание объектных файлов в исполняемый.
	\end{enumerate}
\end{enumerate}

Стоит отметить, что данное деление является довольно условным: так, синтаксический анализатор, семантический анализатор и генератор абстрактного синтаксического дерева типично объединяются в одну единицу, называемую «парсер». Однако, оно довольно показательно с точки зрения объёма и разнообразия задач, решаемых компилятором.
\subsection{Сложность разработки компиляторов}
Разработка современного оптимизирующего промышленного компилятора --- сложная задача, требующая огромных вложений человеческих ресурсов. Больш\'{а}я часть этой сложности обусловлена необходимостью тонкой настройки эвристических методов оптимизации исполняемого кода (которые в общем случае решаются NP-сложными алгоритмами), производимой вручную путём просмотра генерируемого кода и состояний промежуточного представления компилятора. Не говоря о том, что само по себе создание таких эвристик представляет собой зачастую нетривиальную задачу \cite{Muchnick:2004:EIS:989393.989413,Lavery:1995:IPC:626512.626987,Abraham:1996:MSR:243846.243903}, эвристики часто имеют противоположные цели --- например, одни оптимизации увеличивают производительность кода ценой размера исполняемого файла (например, разворачивание циклов), а другие уменьшают размер кода, уменьшая производительность. Помимо этого, в компиляторах чаще всего используются упрощённые модели аппаратного обеспечения, не учитывающие многие эффекты даже первого порядка, не говоря уже о побочных эффектах. Более того, сами правила обнаружения случаев, в которых можно оптимизировать код, создаются человеком, что также трудоёмко и является далеко не исчерпывающим способом увеличения производительности результирующего кода. Помимо этого, от порядка произведения оптимизаций часто зависит итоговая производительность и размер кода исполняемого файла.

В то же время, у настроек эвристик есть фокальные точки --- такие настройки оптимизации, при которых достигается оптимум по какому-либо критерию. Эти фокальные точки могут быть найдены с помощью функции цели. Примером задачи, для которой существуют достаточно хорошие целевые функции, является задача распределения регистров.

В существующих компиляторах также стоит проблема подбора оптимальных настроек компиляции для данной конкретной программы. Чаще всего проще ограничиться стандартной настройкой «максимальная производительность», нежели производить трудоёмкий анализ кода, который так же требует квалификации опытного разработчика компилятора и знания о платформе, для которой генерируется исполняемый файл. Эта задача также может решаться автоматически и, в ряде случаев, более эффективно.

\subsection{Подходы к решению проблемы сложности эвристик}
Попытки настраивать и даже синтезировать \cite{Stephenson:2006:ACC:1269626,Stephenson:2003:MOI:780822.781141} эвристики предпринимались неоднократно. Как уже показали работы \cite{Agakov:2006:UML:1121992.1122412,Bodin98iterativecompilation,FCA2007,Cooper:2005:AAC:1065910.1065921}, задача подбора самих эвристик и их настройки может решаться автоматически.

Принципиально, классическим подходом к этой задаче является итеративная компиляция. Также, в последнее время получили распространение методы машинного обучения и коллективной оптимизации. Далее мы рассмотрим эти подходы.

\subsection{Итеративная компиляция}
Итеративная компиляция --- методика поиска оптимальных по некоторому критерию настроек компилятора, при которой компилируемая программа собирается много раз с одним набором данных на одной и той же программно-аппаратной платформе с разными, выбираемыми, как правило, случайным образом, настройками, с последующим запуском и замером интересующих факторов во время её выполнения (например, времени выполнения). Очевидно, что такой подход страдает от чудовищной неэффективности --- поиск оптимальных настроек для одной программы может занимать месяц машинного времени. Количество необходимых компиляций составляет десятки и сотни запусков \cite{Kisuki:1999:FSI:646347.690219}. Кроме того, такой поиск является весьма ограниченным, поскольку найденные настройки в итоге подходят только для данного набора данных на данной платформе с данным компилятором (вплоть до конкретной версии), и практически никаких общих рекомендаций извлечь из этого процесса не получается.

Неоднократно производились попытки ускорить этот процесс с помощью применения различных методов оптимизации, изменяющих характер поиска настроек с случайного на более направленный. В этом случае задача осложняется чрезвычайно большой многомерностью такой оптимизации --- признаков, по которым опознаются программы и которые можно считать аргументами функции эффективности, насчитываются десятки (имеются ввиду такие признаки, собираемые с исходного кода программы, как средняя глубина вложенности циклов, среднее число вызовов процедур на блок и т.д.). Таким образом, данный способ решения является крайне плохо приспособленным для реального применения.

\subsection{Машинное обучение}
Недавние работы в данной области показали возможность увеличить эффективность итеративной компиляции с помощью машинного обучения, позволяя обеспечить компилятор возможностью подстраиваться под сложные архитектуры и повысить его производительность относительно классических статических компиляторов --- т.е. таких, которые не были специально модифицированы для работы с инструментарием машинного обучения \cite{Dubach:2009:PCO:1669112.1669124,Dubach:2008:EPA:1450095.1450103}.

Далее для понимания связи машинного обучения с компиляцией приведена классическая постановка задачи этого раздела науки.

Имеется множество объектов (ситуаций) и множество возможных ответов (откликов, реакций). Существует некоторая зависимость между ответами и объектами, но она неизвестна. Известна только конечная совокупность прецедентов — пар «объект, ответ», называемая обучающей выборкой. На основе этих данных требуется восстановить зависимость, то есть построить алгоритм, способный для любого объекта выдать достаточно точный ответ. Для измерения точности ответов определённым образом вводится функционал качества.

В нашем случае объектом является исходный код программы с его признаками (такими, как средний размер массивов и среднее число итераций циклов), а ответом --- значение интересующего нас фактора во время исполнения программы (например, объём занимаемой памяти).

Стоит отметить, что предпочтительным является обучение с использованием только производственных запусков компилятора, т.е. без специальных обучающих запусков. Для этого предлагается использовать коллективную оптимизацию, позволяющую пользователям обмениваться данными об успешной оптимизации и не проделывать избыточную работу каждый раз изолированно.

\subsection{Коллективная оптимизация}
Коллективная оптимизация предполагает реализацию некого инструментария, подключаемого к компилятору с целью организации его прозрачной работы с общим репозиторием настроек компиляции. Этот подход является многообещающим, но не лишён сложностей.

А именно, перед реализацией коллективной оптимизации стоит несколько проблем исследовательского и инженерного характера. Инженерная проблема состоит в создании системы, позволяющей прозрачно переиспользовать накопленные другими пользователями знания о произведенных компиляциях и отправлять данные о них без дополнительных действий со стороны конечного пользователя компилятора. Частью решения этой проблемы является плагин к компилятору GCC, предоставляющий возможности произвольного включения выбранных проходов компилятора и обеспечивающий его взаимодействие с репозиторием кода cTuning.org \cite{Fur2009}. В случае более современного компилятора llvm \cite{llvm} плагин имеет более простую организацию, поскольку данный инструмент имеет встроенные возможности произвольного выбора набора производимых оптимизаций, и нужно обеспечить только взаимодействие с репозиторием cTuning. Исследовательская проблема состоит в изучении воздействия различных оптимизаций на различные факторы получаемых программ, такие, как время исполнения и объём используемой памяти.

Коллективная оптимизация может обеспечить эффективность итеративной компиляции без произведения такого большого количества избыточных запусков компилятора. Одним из успешно применяемых подходов к этой задаче предполагает статистическое сравнение эффективности пар наборов оптимизаций. Недавние работы также обнаружили значительно б\'{о}льшую важность обучения на различных наборах данных и на различных архитектурах, нежели обучения на различных программах \cite{springerlink:10.1007/11596110:24}. Это опровергает доминировавшую до этого точку зрения на применение машинного обучения в компиляторах и предлагает новые перспективы в области автоматической настройки компиляции.