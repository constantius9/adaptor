\section{Методология моделирования, применяемая в системе Adaptor}
\subsection{Статистические методы обработки информации}
\subsubsection{Регрессионный анализ}

К регрессионному анализу относятся задачи выявления искажённой случайным <<шумом>> функциональной зависимости интересующего исследователя показателя $Y$ от измеряемых переменных $X_1,...,X_m$. Данными служит таблица экспериментально полученных <<зашумлённых>> значений $Y$ на разных наборах $x_1,...,x_m$ \cite{lag}.

\paragraph{Цели регрессионного анализа}
Цели проведения регрессионного анализа приведены ниже.
\begin{itemize}
    \item Определение степени детерминированности вариации критериальной (зависимой) переменной предикторами (независимыми переменными).
    \item Предсказание значения зависимой переменной с помощью независимой(-ых).
    \item Определение вклада отдельных независимых переменных в вариацию зависимой.
\end{itemize}

Регрессионный анализ нельзя использовать для определения наличия связи между переменными, поскольку наличие такой связи и есть предпосылка для применения анализа.

\paragraph{Математическое определение регрессии}

Строго регрессионную зависимость можно определить следующим образом. Пусть $Y, X_1, X_2,...,X_p$  — случайные величины с заданным совместным распределением вероятностей. Если для каждого набора значений $X_1=x_1,X_2=x_2,...,X_p=x_p$ определено условное математическое ожидание
\begin{equation*}
y(x_1,x_2,...,x_p) = E(Y|X_1 = x_1, X_2 = x_2, ..., X_p = x_p)
\end{equation*}
(уравнение регрессии в общем виде), то функция $y(x_1,x_2,...,x_p)$ называется регрессией величины $Y$ по величинам $X_1,X_2,...,X_p$, а её график — линией регрессии $Y$ по $X_1,X_2,...,X_p$, или уравнением регрессии \cite{applregr}.
Зависимость $Y$ от $X_1,X_2,...,X_p$ проявляется в изменении средних значений $Y$ при изменении $X_1,X_2,...,X_p$. Хотя при каждом фиксированном наборе значений $X_1,X_2,...,X_p$ величина $Y$ остаётся случайной величиной с определённым рассеянием.
Для выяснения вопроса, насколько точно регрессионный анализ оценивает изменение $Y$ при изменении $X_1,X_2,...,X_p$, используется средняя величина дисперсии $Y$ при разных наборах значений $X_1,X_2,...,X_p$ (фактически речь идет о мере рассеяния зависимой переменной вокруг линии регрессии).

\paragraph{Метод наименьших квадратов (расчёт коэффициентов)}

На практике линия регрессии чаще всего ищется в виде линейной функции $Y = b_0 + b_1 X_1 + b_2 X_2 + ... + b_N X_N$ (линейная регрессия), наилучшим образом приближающей искомую кривую \cite{regrmeth}. Делается это с помощью метода наименьших квадратов, когда минимизируется сумма квадратов отклонений реально наблюдаемых $Y$ от их оценок \textit{\^Y} (имеются в виду оценки с помощью прямой линии, претендующей на то, чтобы представлять искомую регрессионную зависимость):
\begin{equation*}
\sum\limits_{k=1}^{M}{(Y_k - \hat{Y}_k)^2} \rightarrow min,
\end{equation*}

где $M$ "--- объём выборки. Этот подход основан на том известном факте, что фигурирующая в приведённом выражении сумма принимает минимальное значение именно для того случая, когда $Y = y(x_1,x_2,...,x_N)$.
Для решения задачи регрессионного анализа методом наименьших квадратов вводится понятие функции невязки
\begin{equation*}
\sigma(\bar{b}) = \frac{1}{2} \sum\limits_{k=1}^{M}{(Y_k - \hat{Y}_k)^2}.
\end{equation*}

Условие минимума функции невязки выражается системой $N+1$  линейных уравнений с $N+1$ неизвестными $b_0...b_n$.
В итоге мы получаем получаем матричное уравнение: $A \times X = B$, которое легко решается методом Гаусса. Полученная матрица будет матрицей, содержащей коэффициенты уравнения линии регрессии:
\begin{equation*}
X = \left\{ \begin{array}{c}
b_0\\
b_1\\
...\\
b_N
\end{array} \right\}.
\end{equation*}

Для получения наилучших оценок необходимо выполнение предпосылок МНК (условий Гаусса-Маркова). В англоязычной литературе такие оценки называются \textit{BLUE} (\textit{Best Linear Unbiased Estimators}) "--- наилучшие линейные несмещенные оценки.

\paragraph{Интерпретация параметров регрессии}

Параметры $b_i$ являются частными коэффициентами корреляции; $(b_i)^2$ интерпретируется как доля дисперсии $Y$, объяснённая $X_i$, при закреплении влияния остальных предикторов, то есть измеряет индивидуальный вклад  в объяснение Y. В случае коррелирующих предикторов возникает проблема неопределённости в оценках, которые становятся зависимыми от порядка включения предикторов в модель. В таких случаях необходимо применение методов анализа корреляционного и пошагового регрессионного анализа \cite{statseval}.
Говоря о нелинейных моделях регрессионного анализа, важно обращать внимание на то, идет ли речь о нелинейности по независимым переменным (с формальной точки зрения легко сводящейся к линейной регрессии), или о нелинейности по оцениваемым параметрам (вызывающей серьёзные вычислительные трудности). При нелинейности первого вида с содержательной точки зрения важно выделять появление в модели членов вида $X_1 X_2$, $X_1 X_2 X_3$, свидетельствующее о наличии взаимодействий между признаками $X_1$, $X_2$ и т. д.

\subsubsection{Перекрёстная проверка}
\label{sscross-validation}
Перекрёстная проверка "--- метод формирования обучающего и тестового множеств для обучения аналитической модели в условиях недостаточности исходных данных или неравномерного представления классов. Для успешного обучения аналитической модели необходимо, чтобы классы были представлены в обучающем множестве примерно в одинаковой пропорции. Однако, если данных недостаточно или процедура сэмплинга при формировании обучающего множества была произведена неудачно, один из классов может оказаться доминирующим. Это может вызвать <<перекос>> в процессе обучения, и доминирующий класс будет рассматриваться как наиболее вероятный. Метод перекрестной проверки позволяет избежать этого \cite{cross-validation}.

В его основе лежит разделение исходного множества данных на $k$ примерно равных блоков, например $k = 5$. Затем на $k - 1$, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется $k$ раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.

Перекрестная проверка имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели. Во-первых, распределение классов оказывается более равномерным, что улучшает качество обучения. Во-вторых, если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная ее оценка будет более достоверной. На практике чаще всего выбирается $k = 10$ (10--проходная перекрестная проверка), когда модель обучается на 9/10 данных и тестируется на 1/10. Исследования показали, что в этом случае получается наиболее достоверная оценка выходной ошибки модели.


\subsection{Метод моделирования эффективности исполнения программ \textit{Velocitas}}
Метод \textit{Velocitas} удовлетворяет требованиям к практически применимому решению задачи моделирования быстродействия программ. Основные положения метода описаны ниже.

В первую очередь устанавливается, какие атрибуты объектов в наборе данных являются признаками (входными параметрами), а какой "--- откликом (выходным параметром). Примерами признаков являются характеристики аппаратного обеспечения, на котором запускалась программа, а отклика "--- время исполнения программы. Выбор выходного параметра, то есть критерия эффективности исполнения программы, из присутствующих в наборе данных, осуществляется исследователем.

После этого создаются дополнительные признаки из уже присутствующих в наборе данных. Например, может быть создан признак <<размер входных данных программы>>, определяемый как произведение числа строк и столбцов в матрице, обрабатываемой программой. Число и содержание дополнительных признаков определяется исследователем на основании личного опыта.

Затем производится фильтрация данных с целью удаления заведомо некорректных измерений. Так, шумом являются все опыты, в результате которых для времени исполнения программы получено неадекватно маленькое значение "--- менее 0,001 с (это минимально измеримое системой время исполнения). Критерии фильтрации также определяются исследователем. Обычно это является элементарной задачей.

Следующим этапом является выполнение ранжирования признаков, присутствующих в наборе данных. Ранжирование выполняется с помощью метода \textit{Earth Importance} \cite{earth-importance}, который является свободной реализацией метода \textit{MARS} "--- \textit{Multivariate Adaptive Regression Splines}. С помощью метода производится оценка важности признаков, после чего для использования при обучении выбираются только признаки с ненулевой важностью.

Построение модели заканчивается выполнением обучения регресионного предсказателя на базе \textit{k Nearest Neighbours}. Квази-оптимальным значением параметра является $k = 30$, однако оно может быть и во многих случаях должно быть настроено индивидуально с учётом имеющегося набора данных. Это можно выполнить с помощью оптимизации гиперпараметров путём сеточного поиска (англ. \textit{grid search}, \cite{grid-search}).

\subsection{Выводы}
Предложен метод моделирования быстродействия программ на различных программно-аппаратных платформах при различных входных данных. Он является удобным для практического применения в инструментарии моделирования и отличается высокими показателями эффективности (см. раздел \ref{sec:evaluation}).