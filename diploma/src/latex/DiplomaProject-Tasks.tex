\section{Задачи}
\begin{enumerate}
\item {Выполнить первоначальное наполнение репозитория данными.
Установить окружение и репозиторий локально и внести туда программы из центрального репозитория.
Собрать небольшое количество признаков для начала работы.\\
Предполагаемый объём работы от общего: 5\%.}
\item {Пронаблюдать влияние набора данных, компилятора и архитектуры на производительность. 
Для этого попробовать перебор разных комбинаций этих параметров (в числе которых и настройки компилятора) и сравнить получаемые результаты. Это нужно для набора данных для последующего машинного обучения на них. 
Это не полный перебор, а небольшой просмотр области поиска с целью выяснения реакции программ на изменения для последующей формализации модели производительности.\\
Предполагаемый объём работы от общего: 10\%.}
\item {Формализовать признаки программ, влияние платформы и настроек компилятора на производительность.
Строим модель производительности программы. Это будет делаться изначально вручную с последующими попытками обобщить до автоматического выбора модели с помощью машинного обучения. Пример: начать с линейной регрессии от одного признака (размера входных данных), дальше обнаруживать нестыковки и добавлять новые признаки.
Полезными моделями могут быть вероятностная (она удобна для представления сравнения 2 программ и легко интерпретируется для понимания человеком), деревья решений (легко интерпретируется, относительно быстро строится и работает).
Другие методы, такие как SVM и kNN, могут тоже быть полезны и возможно будут использоваться — но они лишены такой черты, как простота понимания, почему именно такое решение было выбрано моделью. Это затрудняет дальнейшее развитие проекта (поскольку непонятно, в каком месте модели произошла ошибка). Также, применение методов “ad-hoc” не даёт воспроизводимых результатов, на которых можно хорошо строить модель.\\
Предполагаемый объём работы от общего: 35\%.}
\item {Построить предсказывающий модуль
Он может работать в 2 режимах:
	\begin{enumerate}
	\item Предсказание уровня производительности программы при заданных входных параметрах. Полезно в облачных сервисах и параллельных вычислениях (балансировка загрузки). Это регрессионный анализ.
	\item Выбор оптимальных настроек компилятора для получения максимальной производительности при заданной платформе, программе (которой ещё нет в репозитории известных программ) и множестве наборов входных данных. Возможны даже рекомендации по выбору другого компилятора. Это классификация.
	\end{enumerate}
Сюда же попадает первоначальное обучение предсказателя для начала работы системы.\\
Предполагаемый объём работы от общего: 25\%.}
\item {Анализировать проблемы предсказателя (ошибки неправильной классификации или регрессии) с целью улучшить работу.
Это включает в себя как ручной просмотр моделей экспертами с помощью нашего интрументария (без него это делать крайне неудобно) с целью понимания возможной проблемы, так и попытки автоматически улучшить модель с помощью добавления новых признаков или настроек, не учтённых в модели для этого.
Сюда же попадает дообучение при получении новых данных, таких как запуск программы с новыми данными, на новой платформе или с новым компилятором, или данные о новых программах.\\
Предполагаемый объём работы от общего: 20\%}
\item {Улучшить интеграцию в существующие компиляторы, так чтобы для конечного пользователя работа системы происходила прозрачно (интерфейс работы с компилятором не изменялся). Это нужно для вовлечения большего числа разработчиков и экспертов в компьютерных системах для выявления проблем моделей на этапе 5.\\
Предполагаемый объём работы от общего: 5\%.}
\end{enumerate}

Реализация будет использовать Python в качестве основного языка с возможными вызовами scipy и R для реализации сложной обработки данных. Это простой и удобный, популярный и хорошо поддерживаемый язык с большим количеством библиотек. В случае необходимости можно достигнуть высокой производительности с помощью компилятора PyPy.

В качестве базы данных, репозитория пакетов и веб-сервера используется cM — открытый инструментарий на Python.