# Status #
1. Studying *scipy*. Stopped on Exercise 1.5: Plotting Function to Image.
2. Studying *llvm*. Finished Chapter 2 — Changing the parser and closing thoughts. Next: here
3. Studying *R*. Stopped on Beginning of Studying of R API.
4. Studying *Statistics and ML*. Need to study linear regressions, decision trees, KNN, SVM, pattern matching. Most of this can be studied with AI book from Pasha. Basic Statistics can be studied with Lagutin book. Start **Reading Lagutin** and **Doing Exercises**.
Doing *Lagutin*. Started **Chapter 2 of 26**. Done **Exercise 1.1**. Read **Paragraph 2.1**.
5. Writing *Diploma*. Prepared **Title page**, **Annotation template**, **Bibliography Stub**. Next: Write the **Introdution**. Set **Goals** and Define **Tasks**. Write the **Overview of the Field**.

# Wishes #
1. Automatic performace analysis.
2. Area outlined by articles 1 & 3.
3. Machine Learning — specifically, if possible. Is it possible?

# Questions #
1. What is the status of the new framework?
1. What is the goal?
2. What are the deadlines?
3. What are the opportunities in France? Studying/working.

# Abstracts #
1.  **A Practical Method For Quickly Evaluating Program Optimizations**
	Abstract. This article aims at making iterative optimization practical and usable by speeding up the evaluation of a large range of optimizations. Instead of using a full run to evaluate a single program optimization, we take advantage of periods of stable performance, called phases. For that purpose, we propose a low-overhead phase detection scheme geared toward fast optimization space pruning, using code instrumentation and versioning implemented in a production compiler. Our approach is driven by simplicity and practicality. We show that a simple phase detection scheme can be sufﬁcient for optimization space pruning. We also show it is possible to search for complex optimizations at run-time without resorting to sophisticated dynamic compilation frameworks. Beyond iterative optimization, our approach also enables one to quickly design selftuned applications. Considering 5 representative SpecFP2000 benchmarks, our approach speeds up iterative search for the best program optimizations by a factor of 32 to 962. Phase prediction is 99.4% accurate on average, with an overhead of only 2.6%. The resulting self-tuned implementations bring an average speed-up of 1.4.
2.  Predictive Runtime Code Scheduling for Heterogeneous Architectures
	Heterogeneous architectures are currently widespread. With the advent of easy-to-program general purpose GPUs, virtually every recent desktop computer is a heterogeneous system. Combining the CPU and the GPU brings great amounts of processing power. However, such architectures are often used in a restricted way for domain-specic applications like scientic applications and games, and they tend to be used by a single application at a time. We envision future heterogeneous com puting systems where all their heterogeneous resources are continuously utilized by dierent applications with versioned critical parts to be able to better adapt their behavior and improve execution time, power consumption, response time and other constraints at runtime. Under such a model, adaptive scheduling becomes a critical component. In this paper, we propose a novel predictive user-level scheduler based on past performance history for heterogeneous systems. We developed several scheduling policies and present the study of their impact on system performance. We demonstrate that such scheduler allows multiple applications to fully utilize all available processing resources in CPU/GPU-like systems and consistently achieve speedups ranging from 30% to 40% compared to just using the GPU in a single application mode.
3.  **Finding representative sets of optimizations for adaptive multiversioning applications**
	Abstract. Iterative compilation is a widely adopted technique to optimize programs for di®erent constraints such as performance, code size and power consumption in rapidly evolving hardware and software environments. However, in case of statically compiled programs, it is often restricted to optimizations for a speci¯c dataset and may not be applicable to applications that exhibit di®erent run-time behavior across program phases, multiple datasets or when executed in heterogeneous, reconfgurable and virtual environments. Several frameworks have been recently introduced to tackle these problems and enable run-time optimization and adaptation for statically compiled programs based on static function multiversioning and monitoring of online program behavior. In this article, we present a novel technique to select a minimal set of representative optimization variants (function versions) for such frameworks while avoiding performance loss across available datasets and code-size explosion. We developed a novel mapping mechanism using popular decision tree or rule induction based machine learning techniques to rapidly select best code versions at run-time based on dataset features and minimize selection overhead. These techniques enable creation of self-tuning static binaries or libraries adaptable to changing behavior and environments at run-time using staged compilation that do not require complex recompilation frameworks while e®ectively outperforming traditional single-version non-adaptable code.
