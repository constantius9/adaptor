# Мотивация
1. Многие исследования показывают потенциал, но плохо систематизированы.
2. Инженерная задача по созданию инфраструктуры для коллективной оптимизации не решена до сих пор.
2. Конечным пользователям компиляторов мешает именно отсутствие инструментария, который помог бы им пользоваться обучаемым компилятором так же, как обычным (интерфейс чёрного ящика).
2. В целом это популярная в последнее время тема — Intel запустил Exascale Lab, также IBM и ARM очень заинтересованы и хотят финансировать эти исследования.

# Неформальная постановка задачи

Цель — разработать систему сбора, систематизации, формализации данных о производительности компилируемых программ в зависимости от настроек компилятора, а также выполняющую функции поддержки базы знаний и обучения с целью:

1. Предсказания производительности программ
2. Оптимизации производительности программ путём изменения настроек компилятора

Пока рассматриваем только 1 критерий — производительность.

# Краткий план

1. **[05%]** Выполнить первоначальное наполнение репозитория данными.
Установить окружение и репозиторий локально и внести туда программы из центрального репозитория.
Собрать небольшое количество признаков для начала работы.
2. **[10%]** Пронаблюдать влияние набора данных, компилятора и архитектуры на производительность. 
Для этого попробовать перебор разных комбинаций этих параметров (в числе которых и настройки компилятора) и сравнить получаемые результаты. Это нужно для набора данных для последующего машинного обучения на них. 
Это не полный перебор, а небольшой просмотр области поиска с целью выяснения реакции программ на изменения для последующей формализации модели производительности.
3. **[35%]** Формализовать признаки программ, влияние платформы и настроек компилятора на производительность.
Строим модель производительности программы. Это будет делаться изначально вручную с последующими попытками обобщить до автоматического выбора модели с помощью машинного обучения. Пример: начать с линейной регрессии от одного признака (размера входных данных), дальше обнаруживать нестыковки и добавлять новые признаки.
Полезными моделями могут быть вероятностная (она удобна для представления сравнения 2 программ и легко интерпретируется для понимания человеком), деревья решений (легко интерпретируется, относительно быстро строится и работает).
Другие методы, такие как SVM и kNN, могут тоже быть полезны и возможно будут использоваться — но они лишены такой черты, как простота понимания, почему именно такое решение было выбрано моделью. Это затрудняет дальнейшее развитие проекта (поскольку непонятно, в каком месте модели произошла ошибка). Также, применение методов “ad-hoc” не даёт воспроизводимых результатов, на которых можно хорошо строить модель.
4. **[25%]** Построить предсказывающий модуль
Он может работать в 2 режимах:
	1. Предсказание уровня производительности программы при заданных входных параметрах. Полезно в облачных сервисах и параллельных вычислениях (балансировка загрузки). Это регрессионный анализ.
	2. Выбор оптимальных настроек компилятора для получения максимальной производительности при заданной платформе, программе (которой ещё нет в репозитории известных программ) и множестве наборов входных данных. Возможны даже рекомендации по выбору другого компилятора. Это классификация.
Сюда же попадает первоначальное обучение предсказателя для начала работы системы.
5. **[20%]** Анализировать проблемы предсказателя (ошибки неправильной классификации или регрессии) с целью улучшить работу.
Это включает в себя как ручной просмотр моделей экспертами с помощью нашего интрументария (без него это делать крайне неудобно) с целью понимания возможной проблемы, так и попытки автоматически улучшить модель с помощью добавления новых признаков или настроек, не учтённых в модели для этого.
Сюда же попадает дообучение при получении новых данных, таких как запуск программы с новыми данными, на новой платформе или с новым компилятором, или данные о новых программах.
6. **[05%]** Улучшить интеграцию в существующие компиляторы, так чтобы для конечного пользователя работа системы происходила прозрачно (интерфейс работы с компилятором не изменялся). Это нужно для вовлечения большего числа разработчиков и экспертов в компьютерных системах для выявления проблем моделей на этапе 5.

Реализация будет использовать Python в качестве основного языка с возможными вызовами scipy и R для реализации сложной обработки данных. Это простой и удобный, популярный и хорошо поддерживаемый язык с большим количеством библиотек. В случае необходимости можно достигнуть высокой производительности с помощью компилятора PyPy.

В качестве базы данных, репозитория пакетов и веб-сервера используется cM — открытый инструментарий на Python.