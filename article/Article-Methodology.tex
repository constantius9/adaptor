\section{Методология моделирования, применяемая в системе \textit{Adaptor}}
\subsection{Метод моделирования быстродействия программ \textit{Velocitas}}

Метод \textit{Velocitas} удовлетворяет требованиям к практически применимому решению задачи моделирования быстродействия программ. Основные положения метода описаны ниже.

В первую очередь устанавливается, какие атрибуты объектов в наборе данных являются признаками (входными параметрами), а какой "--- откликом (выходным параметром). Примерами признаков являются характеристики аппаратного обеспечения, на котором запускалась программа, а отклика "--- время исполнения программы. Выбор выходного параметра, то есть критерия эффективности исполнения программы, из присутствующих в наборе данных, осуществляется исследователем.

После этого создаются дополнительные признаки из уже присутствующих в наборе данных. Например, может быть создан признак <<размер входных данных программы>>, определяемый как произведение числа строк и столбцов в матрице, обрабатываемой программой. Число и содержание дополнительных признаков определяется исследователем на основании личного опыта.

Затем производится фильтрация данных с целью удаления заведомо некорректных измерений. Так, шумом являются все опыты, в результате которых для времени исполнения программы получено неадекватно маленькое значение "--- менее $0,001 \textup{с}$ (это минимально измеримое системой время исполнения). Критерии фильтрации также определяются исследователем. Обычно это является элементарной задачей.

Следующим этапом является выполнение ранжирования признаков, присутствующих в наборе данных. Ранжирование выполняется с помощью метода \textit{Earth Importance} \cite{earth-importance}, который является свободной реализацией метода \textit{MARS} "--- \textit{Multivariate Adaptive Regression Splines}. С помощью метода производится оценка важности признаков, после чего для использования при обучении выбираются только признаки с ненулевой важностью.

Построение модели заканчивается выполнением обучения регресионного предсказателя на базе \textit{k Nearest Neighbours}. Квази-оптимальным значением параметра является $k = 30$, однако оно может быть и во многих случаях должно быть настроено индивидуально с учётом имеющегося набора данных. Это можно выполнить с помощью оптимизации гиперпараметров путём сеточного поиска (англ. \textit{grid search}, \cite{grid-search}).

Предложенный метод моделирования быстродействия программ практически применим в инструментарии моделирования \textit{Adaptor} и отличается высокими показателями эффективности (см. раздел \ref{sec:evaluation}).

\subsection{Метод измерения времени исполнения исследуемой программы}
\subsubsection{Время исполнения программы}
Точное измерение времени исполнения программы может представлять сложности ввиду возможных колебаний из-за изменения загрузки системы другими задачами. Принципиально, рекомендуется выполнять эксперименты на системе, не занятой другими задачами. Однако даже в таком случае системные процессы или разница в решениях, принятых планировщиком процессов, могут оказать значительное воздействие на измерение времени. Подробнее о механизмах, применяемых в планировщиках процессов в современных ОС и о возможном воздействии на время выполнения задачи, смотри источник~\cite{scheduling}.

Для устранения описанных проблем необходимо производить несколько запусков программы. Программа запускается 3 раза и берётся минимальное время её выполнения. Это время будет наиболее точно отражать производительность программно-аппаратной платформы, поскольку увеличение времени выполнения происходит в связи с интерференцией данного процесса с другими и общим состоянием системы. Как показали эксперименты (результаты в этой работе не приводятся), воздействие кэширования на производительность программы из тестового набора при многократном запуске при текущей реализации инструментария не наблюдается.

В случае внешнего измерения времени исполнения влияние оказывают также накладные расходы, связанные с запуском программы из системы. Для их исключения измерять время исполнения лучше изнутри программы и выводить его, например, в стандартный поток ошибок. Таким образом измерение времени производится в пакете тестирования производительности \textit{Polybench}~\cite{polybench}.

Внутреннее измерение времени исполнения обеспечивает большую точность, однако, оно требует поддержки на уровне исходного кода. Очевидно, что для универсального инструментария запуска оптимизационных экспериментов такое решение неприемлемо, поскольку должно быть возможно измерение времени выполнения программ, никак специально не подготовленных для этого.

По этой причине система измеряет время исполнения извне. Невысокая точность измерения при этом устраняется с помощью калибровки (см.~ниже). При этом также стоит отметить, что погрешность, вносимая внешним измерением, является систематической и не оказывает влияния на относительное время выполнения разных версий программы, что является наиболее важным в данной задаче.


\subsubsection{Калибровка времени исполнения программы}
\label{sssect:calibration}
Помимо отмеченных сложностей, есть сложность измерения маленьких интервалов времени. Если время исполнения программы находится на уровне 1 мс (таково временное разрешение системного вызова \textit{Unix} \texttt{gettimeofday}), то даже если запускать программу несколько раз, колебания измерений окажутся настолько большими, что сделают результат неточным. Для устранения этой проблемы предлагается специальный алгоритм калибровки, схема которого приведена ниже. Он также позволяет уменьшить влияние колебаний времени исполнения.

\begin{enumerate}
    \item Положить $n = 0, t = 0, d_{rel} = 1$.
    \item Исполнить программу однократно и измерить время её выполнения.
    \item Если время выполнения более 1 секунды, положить $n = -1$.
    \item Производить следующий цикл, пока $t < 1$ и $d_{rel} > 0,05$. Иначе перейти к шагу 9.
    \item Увеличить n на 1: $n = n + 1$.
    \item Вычислить число запусков программы как $number = 10^{n}$.
    \item Запустить программу $number$ раз, измеряя время выполнения. Повторить это 3 раза. Среди результатов выбрать минимум и присвоить его $t$. Вычислить относительную дисперсию результатов и присвоить её величине $d_{rel}$.
    \item Перейти к шагу 4.
    \item Получить время исполнения программы как $t / number$.
\end{enumerate}

В ряде случаев также используется сравнение измеренного времени исполнения с <<реальным>>. Хотя на практике сложно измерить время реального исполнения (т.е. за исключением времени запуска), время запуска можно вычислить, запустив программу, которая ничего не делает, и измерив время её исполнения. Затем можно вносить поправку на время запуска в каждое измерение (для устранения систематической методической погрешности). Проблема этого решения в том, что требуется очень точное измерение времени запуска пустой программы, но при применении тех же методов это принципиально невозможно "--- время её исполнения также будет сильно колебаться в зависимости от загрузки системы и практически случайного воздействия планировщика задач в текущем состоянии системы.

Оценку предложенных методов измерения времени можно произвести путём сравнения измеренного времени исполнения с временем, заданным таймером с помощью вызова функции \texttt{usleep} стандартной библиотеки языка \textit{С} изнутри программы.

Стоит отметить, что существуют постоянные расходы на запуск программы из нашей системы и их можно вычесть из измеренного времени для повышения точности измерения. Для этого мы вычисляем время выполнения пустой программы, а затем вычитаем его из каждого измеренного результата выполнения реальных программ.